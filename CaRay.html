<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>NanoAI RT</title>
  <style>
.container {
  background-color: #ffffff;
  text-align: left;
  padding: 16px;
  border-radius: 8px;
}
.msg {
    padding: 5px;
    background-color: #eee;
}
.msgUsr {
    padding: 5px;
    background-color: #e4eefd;
}
.curMsg {
    padding: 5px;
    background-color: #e6ffd9;
}
h1 {
    margin: 5px;
    font-size: 20px;
}
</style>
</head>
<body>
  <H1>Let's talk!</H1>
  <div class="container">
    <div class="messages"></div>
    <div class="curMsg"></div>
    <div id="statusLog" style="background:#f0f0f0;padding:10px;margin-top:10px;font-family:monospace;font-size:14px;border:1px solid #ccc;">
      <strong>Status Log:</strong><br/>
    </div>
  </div>
<script>

let micTrack = null;
let isRecording = false;
let dc;
let pc; // <--- æå‡ pc ä½œç”¨åŸŸ
let ms; // <--- æå‡ ms ä½œç”¨åŸŸ

document.addEventListener("keydown", (e) => {
  if (e.code === "Space" && !isRecording) {
    e.preventDefault();
    isRecording = true;
    if (micTrack) micTrack.enabled = true;
    appendStatusLog("ğŸ¤ é–‹å§‹æ”¶éŸ³");
  }
});

document.addEventListener("keyup", (e) => {
  if (e.code === "Space" && isRecording) {
    e.preventDefault();
    isRecording = false;
    if (micTrack) micTrack.enabled = false;
    appendStatusLog("ğŸ›‘ åœæ­¢æ”¶éŸ³");
  }
});

function appendStatusLog(text) {
  const log = document.getElementById("statusLog");
  const line = document.createElement("div");
  const timestamp = `[${new Date().toLocaleTimeString("zh-TW", { hour12: false })}] `;
  if (text.includes("<pre>")) {
    line.innerHTML = timestamp + text;
  } else {
    line.textContent = timestamp + text;
  }
  log.appendChild(line);
  log.scrollTop = log.scrollHeight;
}

async function init() {
  const EPHEMERAL_KEY = "{{ $json.client_secret.value }}";
  pc = new RTCPeerConnection(); // <--- è³¦å€¼çµ¦å…¨å±€ pc

  const audioEl = document.createElement("audio");
  audioEl.autoplay = true;
  pc.ontrack = e => audioEl.srcObject = e.streams[0];

  try {
    ms = await navigator.mediaDevices.getUserMedia({ audio: true }); // <--- è³¦å€¼çµ¦å…¨å±€ ms
    micTrack = ms.getTracks()[0];
    micTrack.enabled = false;
    pc.addTrack(micTrack);
  } catch (err) {
    appendStatusLog(`âŒ ç„¡æ³•å–å¾—éº¥å…‹é¢¨æ¬Šé™: ${err.message}`);
    return;
  }

  dc = pc.createDataChannel("oai-events");
  dc.addEventListener("message", (e) => {
    handleResponse(e);
  });

  dc.onopen = () => appendStatusLog("ğŸ”— DataChannel å·²é–‹å•Ÿ");
  dc.onclose = () => appendStatusLog("ğŸšª DataChannel å·²é—œé–‰ (å¤–éƒ¨äº‹ä»¶æˆ– EndSession)");


  try {
    const offer = await pc.createOffer();
    await pc.setLocalDescription(offer);

    const baseUrl = "https://api.openai.com/v1/realtime";
    const model = "gpt-4o-realtime-preview-2024-12-17";
    const sdpResponse = await fetch(`${baseUrl}?model=${model}`, {
      method: "POST",
      body: offer.sdp,
      headers: {
        Authorization: `Bearer ${EPHEMERAL_KEY}`,
        "Content-Type": "application/sdp"
      },
    });

    if (!sdpResponse.ok) {
        const errorText = await sdpResponse.text();
        throw new Error(`SDP äº¤æ›å¤±æ•—: ${sdpResponse.status} ${errorText}`);
    }

    const answer = {
      type: "answer",
      sdp: await sdpResponse.text(),
    };
    await pc.setRemoteDescription(answer);
    appendStatusLog("ğŸš€ Realtime é€£ç·šå·²å»ºç«‹");

  } catch (err) {
    appendStatusLog(`âŒ åˆå§‹åŒ– Realtime é€£ç·šå¤±æ•—: ${err.message}`);
  }
}

function handleResponse(e) {
  const obj = JSON.parse(e.data);
  appendStatusLog(`ğŸ“¥ Received event: ${obj.type}`);

  if (obj.type === 'response.audio_transcript.done') {
    appendStatusLog(`ğŸ¤– AI æœ€çµ‚èªéŸ³ç¨¿: ${obj.transcript}`);
    document.querySelector('.curMsg').innerHTML = "";
    document.querySelector('.messages').innerHTML += `<div class='msg'>AI: ${obj.transcript}</div><br/>`;
  }

  if (obj.type === 'conversation.item.input_audio_transcription.completed') {
    appendStatusLog(`ğŸ‘¤ ä½¿ç”¨è€…æœ€çµ‚èªéŸ³ç¨¿: ${obj.transcript}`);
    document.querySelector('.curMsg').innerHTML = "";
    document.querySelector('.messages').innerHTML += `<div class='msgUsr'>User: ${obj.transcript}</div><br/>`;
  }

  if (obj.type === 'response.audio_transcript.delta' || obj.type === 'conversation.item.input_audio_transcription.delta') {
    document.querySelector('.curMsg').innerHTML += obj.delta;
  }

  if (obj.type === "response.function_call_arguments.done") {
    appendStatusLog(`ğŸ§ª function_call_arguments.done çš„å®Œæ•´ç‰©ä»¶ï¼š<pre>${JSON.stringify(obj, null, 2)}</pre>`);

    const toolName = obj.name;
    const argsStr = obj.arguments;
    const callIdForTool = obj.call_id;
    let args;

    try {
      args = JSON.parse(argsStr);
    } catch (parseError) {
      appendStatusLog(`âŒ è§£æ arguments å¤±æ•—: ${parseError.message}`);
      args = {};
      if (dc && dc.readyState === "open") {
        dc.send(JSON.stringify({
          type: "conversation.item.create",
          item: {
            type: "function_call_output",
            call_id: callIdForTool,
            output: JSON.stringify({ error: `Failed to parse arguments: ${parseError.message}` })
          }
        }));
      }
      return;
    }

    appendStatusLog(`ğŸ“ GPT è¦å‘¼å«å·¥å…·ï¼š${toolName}ï¼Œåƒæ•¸ï¼š${argsStr}`);

    async function fakeKYCFunction(id) {
        const itemsString = `{{ JSON.stringify($("Google Sheets").all()) }}`;
        let items = [];
        try {
            items = JSON.parse(itemsString);
            if (!Array.isArray(items)) throw new Error("Google Sheets data is not an array.");
        } catch (err) {
            appendStatusLog(`âŒ è§£æ Google Sheets è³‡æ–™å¤±æ•—: ${err.message}`);
            return { id, error: true, message: `ç„¡æ³•è®€å– KYC è³‡æ–™ä¾†æº: ${err.message}` };
        }

        try {
          if (!id) throw new Error("KYC æŸ¥è©¢è«‹æä¾› id");
          const rows = items.map(item => item.json || item);
          const matched = rows.find(row => String(row.id).trim() === String(id).trim());

          if (!matched) {
            throw new Error(`æ‰¾ä¸åˆ° ID ç‚º ${id} çš„ KYC è³‡æ–™`);
          }
          return {
            id: matched.id,
            name: matched["å§“å"], 
            school: matched["å°±è®€åœ‹å°"],
            hobby: matched["èˆˆè¶£"],
            siblings: matched["å¹¾å€‹å…„å¼Ÿå§Šå¦¹"],
            info: "ä½¿ç”¨è€… KYC è³‡æ–™æˆåŠŸå–å¾—"
          };
        } catch (err) {
          return { id, error: true, message: err.message };
        }
    }

    async function fakeInfoSender(id, intention) { // å¦‚æœæ‚¨é‚„éœ€è¦é€™å€‹å·¥å…·
      appendStatusLog(`â„¹ï¸ æ¨¡æ“¬ info_sender: id=${id}, intention=${intention}`);
      return { id, status: "sent", intention, message: "è³‡è¨Šå·²æ¨¡æ“¬ç™¼é€" };
    }

    (async () => {
      let resultForAI = {}; // åˆå§‹åŒ–ï¼Œç¢ºä¿æ‰€æœ‰åˆ†æ”¯éƒ½æœ‰è³¦å€¼

      try {
        if (toolName === "KYC_info_retriever") {
          resultForAI = await fakeKYCFunction(args.id);
        } else if (toolName === "SaveData") {
          appendStatusLog(`â¡ï¸ æº–å‚™å°‡æ•¸æ“šç™¼é€åˆ° n8n ä»¥åŸ·è¡Œ SaveData...`);
          if (!args.id || !args.intention || !args.intention_classified) {
            const missingParams = [];
            if (!args.id) missingParams.push("id");
            if (!args.intention) missingParams.push("intention");
            if (!args.intention_classified) missingParams.push("intention_classified");
            const errorMessage = `SaveData ç¼ºå°‘å¿…è¦åƒæ•¸: ${missingParams.join(", ")}`;
            appendStatusLog(`âŒ ${errorMessage}`);
            resultForAI = { error: true, message: errorMessage };
          } else {
            const saveDataPayload = {
              id: args.id,
              intention: args.intention,
              intention_classified: args.intention_classified
            };
            const n8nWebhookUrl = "https://mmbcolab.app.n8n.cloud/webhook/SaveData"; // ä½¿ç”¨ç”Ÿç”¢ URL
            try {
              const response = await fetch(n8nWebhookUrl, {
                method: "POST",
                headers: { "Content-Type": "application/json" },
                body: JSON.stringify(saveDataPayload),
              });
              if (!response.ok) {
                const errorText = await response.text();
                appendStatusLog(`âŒ n8n Webhook éŒ¯èª¤: ${response.status} - ${errorText}`);
                resultForAI = { error: true, message: `n8n Webhook è™•ç†å¤±æ•—: ${response.status}` };
              } else {
                appendStatusLog(`âœ… æ•¸æ“šå·²æˆåŠŸç™¼é€åˆ° n8n Webhook.`);
                resultForAI = {
                  status: "success",
                  message: "è³‡æ–™å·²æˆåŠŸè¨˜éŒ„ã€‚",
                  details_sent_to_n8n: saveDataPayload
                };
              }
            } catch (networkError) {
              appendStatusLog(`âŒ ç™¼é€æ•¸æ“šåˆ° n8n Webhook æ™‚ç¶²çµ¡éŒ¯èª¤: ${networkError.message}`);
              resultForAI = { error: true, message: `ç„¡æ³•é€£æ¥åˆ° n8n æœå‹™: ${networkError.message}` };
            }
          }
        } else if (toolName === "EndSession") {
          appendStatusLog("ğŸ”„ æ­£åœ¨åŸ·è¡Œ EndSession å·¥å…·...");

          // å˜—è©¦å‘ AI è¿”å›å·¥å…·åŸ·è¡ŒæˆåŠŸçš„æ¶ˆæ¯ (åœ¨é—œé–‰ dc ä¹‹å‰)
          if (dc && dc.readyState === "open") {
            dc.send(JSON.stringify({
              type: "conversation.item.create",
              item: {
                type: "function_call_output",
                call_id: callIdForTool,
                output: JSON.stringify({ status: "session_ended", message: "Session termination initiated by EndSession tool." })
              }
            }));
            appendStatusLog("ğŸ“¤ å·²å˜—è©¦å›å‚³ EndSession å·¥å…·çµæœçµ¦ Assistant");
          } else {
            appendStatusLog("âš ï¸ DataChannel æœªé–‹å•Ÿï¼Œç„¡æ³•å›å‚³ EndSession å·¥å…·çµæœçµ¦ Assistant");
          }
          
          // é—œé–‰ DataChannel
          if (dc && dc.readyState === "open") { // å†æ¬¡æª¢æŸ¥ï¼Œä»¥é˜²ä¸Šé¢ç™¼é€æ™‚ç‹€æ…‹æ”¹è®Š
            dc.close();
            appendStatusLog("ğŸšª DataChannel å·²ä¸»å‹•é—œé–‰ (by EndSession)");
          } else if (dc) {
            appendStatusLog(`ğŸšª DataChannel ç‹€æ…‹: ${dc.readyState} (æœªä¸»å‹•é—œé–‰ by EndSession)`);
          }


          // é—œé–‰ RTCPeerConnection
          if (pc) {
            pc.close();
            appendStatusLog("ğŸ”Œ RTCPeerConnection å·²ä¸»å‹•é—œé–‰ (by EndSession)");
          }

          // åœæ­¢æœ¬åœ°åª’é«”è»Œé“
          if (ms && typeof ms.getTracks === 'function') {
            ms.getTracks().forEach(track => track.stop());
            appendStatusLog("ğŸ¤ æœ¬åœ°åª’é«”è»Œé“ (ms) å·²åœæ­¢ (by EndSession)");
          } else if (micTrack && typeof micTrack.stop === 'function') {
            micTrack.stop();
            appendStatusLog("ğŸ¤ æœ¬åœ°åª’é«”è»Œé“ (micTrack) å·²åœæ­¢ (by EndSession)");
          }
          
          appendStatusLog("ğŸ æœå‹™çµæŸ (EndSession tool åŸ·è¡Œå®Œç•¢)");
          resultForAI = { status: "session_ended_locally", message: "Local resources released." }; // é€™å€‹çµæœä¸»è¦ç”¨æ–¼æœ¬åœ°æ—¥èªŒï¼Œå› ç‚º dc å¯èƒ½å·²é—œé–‰

          // å¯é¸ï¼šæª¢æŸ¥ WebRTC é€£æ¥ç‹€æ…‹ï¼Œç”¨æ–¼èª¿è©¦
          if (pc && (pc.connectionState === "disconnected" ||
              pc.connectionState === "closed" ||
              pc.connectionState === "failed")) {
            appendStatusLog("âœ… WebRTC é€£æ¥ç‹€æ…‹ç¢ºèªï¼šå·²ä¸­æ–·/é—œé–‰ã€‚");
          } else if (pc) {
            appendStatusLog(`âš ï¸ WebRTC é€£æ¥ç‹€æ…‹: ${pc.connectionState} (å¯èƒ½æœªç«‹å³å®Œå…¨é—œé–‰)`);
          }

        } else { // è™•ç†æœªçŸ¥å·¥å…·
          appendStatusLog(`â“ æœªçŸ¥çš„å·¥å…·åç¨±: ${toolName}`);
          resultForAI = { error: true, message: `æœªçŸ¥çš„å·¥å…·åç¨±: ${toolName}`, tool_name: toolName };
        }

        // --- å‘ AI Assistant å›å‚³å·¥å…·åŸ·è¡Œçµæœ (é™¤äº† EndSessionï¼Œå®ƒå·²åœ¨å…§éƒ¨è™•ç†) ---
        if (toolName !== "EndSession") {
          appendStatusLog(`ğŸ›  ${toolName} å·¥å…·åŸ·è¡Œçµæœ (æº–å‚™å›å‚³çµ¦AI)ï¼š${JSON.stringify(resultForAI)}`);
          if (dc && dc.readyState === "open") {
            dc.send(JSON.stringify({
              type: "conversation.item.create",
              item: {
                type: "function_call_output",
                call_id: callIdForTool,
                output: JSON.stringify(resultForAI)
              }
            }));
            appendStatusLog(`ğŸ“¤ å·²å›å‚³ ${toolName} å·¥å…·çµæœ (call_id: ${callIdForTool}) çµ¦ Assistant`);
          } else {
            appendStatusLog(`âŒ DataChannel æœªé–‹å•Ÿï¼Œç„¡æ³•å›å‚³ ${toolName} å·¥å…·çµæœ (call_id: ${callIdForTool})`);
          }
        }

      } catch (toolExecutionError) {
        appendStatusLog(`âŒ å·¥å…·åŸ·è¡Œæˆ–å›å‚³æ™‚ç™¼ç”Ÿåš´é‡éŒ¯èª¤: ${toolExecutionError.message}. Stack: ${toolExecutionError.stack}`);
        if (dc && dc.readyState === "open") { // ä»ç„¶å˜—è©¦é€šéé–‹æ”¾çš„ dc å›å‚³éŒ¯èª¤
          dc.send(JSON.stringify({
            type: "conversation.item.create",
            item: {
              type: "function_call_output",
              call_id: callIdForTool,
              output: JSON.stringify({ error: true, message: `å·¥å…·åŸ·è¡ŒæœŸé–“ç™¼ç”Ÿå…§éƒ¨éŒ¯èª¤: ${toolExecutionError.message}` })
            }
          }));
          appendStatusLog(`ğŸ“¤ å·²å›å‚³å·¥å…·åŸ·è¡Œåš´é‡éŒ¯èª¤ (call_id: ${callIdForTool}) çµ¦ Assistant`);
        }
      }
    })();
  }

  if (obj.type === "response.output_item.done") {
    const content = obj.content?.text;
    if (content) {
      document.querySelector('.curMsg').innerHTML = "";
      document.querySelector('.messages').innerHTML += `<div class='msg'>AI: ${content}</div><br/>`;
      appendStatusLog(`ğŸ—£ï¸ AI æœ€çµ‚å›æ‡‰å…§å®¹: ${content}`);
    }
  }

  if (obj.type === "output_audio_buffer.stopped"){
    // æ ¹æ“šæ‚¨çš„æµç¨‹æ±ºå®šé€™è£¡æ˜¯å¦éœ€è¦æ“ä½œ
  }

  if (obj.type === "error") {
    appendStatusLog(`âŒ ç™¼ç”Ÿ API éŒ¯èª¤ï¼š<pre>${JSON.stringify(obj, null, 2)}</pre>`);
  }
}

init().catch(err => {
  appendStatusLog(`âŒ åˆå§‹åŒ–éç¨‹ä¸­ç™¼ç”Ÿæœªæ•ç²çš„éŒ¯èª¤: ${err.message}`);
});

</script>
</body>
</html>